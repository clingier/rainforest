{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clingier\\anaconda3\\envs\\rainforest\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\clingier\\anaconda3\\envs\\rainforest\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\clingier\\anaconda3\\envs\\rainforest\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[44.544]</td>\n",
       "      <td>[2531.25]</td>\n",
       "      <td>[45.1307]</td>\n",
       "      <td>[5531.25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[39.9615]</td>\n",
       "      <td>[7235.16]</td>\n",
       "      <td>[46.0452]</td>\n",
       "      <td>[11283.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[39.136]</td>\n",
       "      <td>[562.5]</td>\n",
       "      <td>[42.272]</td>\n",
       "      <td>[3281.25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[51.4206]</td>\n",
       "      <td>[1464.26]</td>\n",
       "      <td>[55.1996]</td>\n",
       "      <td>[4565.04]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[50.0854]</td>\n",
       "      <td>[947.461]</td>\n",
       "      <td>[52.5293]</td>\n",
       "      <td>[10852.7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>fe8d9ac40</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[53.472]</td>\n",
       "      <td>[93.75]</td>\n",
       "      <td>[54.096]</td>\n",
       "      <td>[843.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>fea6b438a</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[43.5787]</td>\n",
       "      <td>[2531.25]</td>\n",
       "      <td>[45.7653]</td>\n",
       "      <td>[4031.25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>ff2eb9ce5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[15.2267]</td>\n",
       "      <td>[5906.25]</td>\n",
       "      <td>[16.0213]</td>\n",
       "      <td>[8250.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>ffb8d8391</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[14.3467]</td>\n",
       "      <td>[4781.25]</td>\n",
       "      <td>[16.6987]</td>\n",
       "      <td>[10406.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>ffb9a7b9a</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[40.32]</td>\n",
       "      <td>[3187.5]</td>\n",
       "      <td>[41.0133]</td>\n",
       "      <td>[5062.5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1132 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recording_id species_id songtype_id      t_min      f_min      t_max  \\\n",
       "0       003bec244       [14]         [1]   [44.544]  [2531.25]  [45.1307]   \n",
       "1       006ab765f       [23]         [1]  [39.9615]  [7235.16]  [46.0452]   \n",
       "2       007f87ba2       [12]         [1]   [39.136]    [562.5]   [42.272]   \n",
       "3       0099c367b       [17]         [4]  [51.4206]  [1464.26]  [55.1996]   \n",
       "4       009b760e6       [10]         [1]  [50.0854]  [947.461]  [52.5293]   \n",
       "...           ...        ...         ...        ...        ...        ...   \n",
       "1127    fe8d9ac40       [13]         [1]   [53.472]    [93.75]   [54.096]   \n",
       "1128    fea6b438a        [4]         [1]  [43.5787]  [2531.25]  [45.7653]   \n",
       "1129    ff2eb9ce5        [0]         [1]  [15.2267]  [5906.25]  [16.0213]   \n",
       "1130    ffb8d8391        [5]         [1]  [14.3467]  [4781.25]  [16.6987]   \n",
       "1131    ffb9a7b9a       [18]         [1]    [40.32]   [3187.5]  [41.0133]   \n",
       "\n",
       "          f_max  \n",
       "0     [5531.25]  \n",
       "1     [11283.4]  \n",
       "2     [3281.25]  \n",
       "3     [4565.04]  \n",
       "4     [10852.7]  \n",
       "...         ...  \n",
       "1127   [843.75]  \n",
       "1128  [4031.25]  \n",
       "1129   [8250.0]  \n",
       "1130  [10406.2]  \n",
       "1131   [5062.5]  \n",
       "\n",
       "[1132 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/raw/RCSAD/train_tp.csv\")\n",
    "test = pd.read_csv(\"../data/raw/RCSAD/sample_submission.csv\")\n",
    "train.groupby(\"recording_id\").agg(lambda x: list(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "import soundfile as sf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, period=10, transforms=None, data_path=\"../data/raw/RCSAD/train\", train=True):\n",
    "        self.period = period\n",
    "        self.transforms = transforms\n",
    "        self.data_path = data_path\n",
    "        self.train = train\n",
    "\n",
    "        if train:\n",
    "            dfgby = df.groupby(\"recording_id\").agg(lambda x: list(x)).reset_index()\n",
    "            self.recording_ids = dfgby[\"recording_id\"].values\n",
    "            self.species_ids = dfgby[\"species_id\"].values\n",
    "            self.t_mins = dfgby[\"t_min\"].values\n",
    "            self.t_maxs = dfgby[\"t_max\"].values\n",
    "        else:\n",
    "            self.recording_ids = df[\"recording_id\"].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.recording_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        recording_id = self.recording_ids[idx]\n",
    "        if self.train:\n",
    "            species_id = self.species_ids[idx]\n",
    "            t_min, t_max = self.t_mins[idx], self.t_maxs[idx]\n",
    "        else:\n",
    "            species_id = [0]\n",
    "            t_min, t_max = [0], [0]\n",
    "        \n",
    "        y, sr = sf.read(f\"{self.data_path}/{recording_id}.flac\")\n",
    "\n",
    "        len_y = len(y)\n",
    "        effective_length = sr * self.period\n",
    "        rint = np.random.randint(len(t_min))\n",
    "        tmin, tmax = round(sr * t_min[rint]), round(sr * t_max[rint])\n",
    "\n",
    "        if len_y < effective_length:\n",
    "            start = np.random.randint(effective_length - len_y)\n",
    "            new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "            new_y[start:start+len_y] = y\n",
    "            y = new_y.astype(np.float32)\n",
    "        elif len_y > effective_length:\n",
    "            center = round((tmin + tmax) / 2)\n",
    "            big = center - effective_length\n",
    "            if big < 0:\n",
    "                big = 0\n",
    "            start = np.random.randint(big, center)\n",
    "            y = y[start:start+effective_length]\n",
    "            if len(y) < effective_length:\n",
    "                new_y = np.zeros(effective_length, dtype=y.dtype)\n",
    "                start1 = np.random.randint(effective_length - len(y))\n",
    "                new_y[start1:start1+len(y)] = y\n",
    "                y = new_y.astype(np.float32)\n",
    "            else:\n",
    "                y = y.astype(np.float32)\n",
    "        else:\n",
    "            y = y.astype(np.float32)\n",
    "            start = 0\n",
    "        \n",
    "        if self.transforms:\n",
    "            y = self.transforms(samples=y, sample_rate=sr)\n",
    "            \n",
    "        start_time = start / sr\n",
    "        end_time = (start + effective_length) / sr\n",
    "\n",
    "        label = np.zeros(24, dtype='f')\n",
    "\n",
    "        if self.train:\n",
    "            for i in range(len(t_min)):\n",
    "                if (t_min[i] >= start_time) & (t_max[i] <= end_time):\n",
    "                    label[species_id[i]] = 1\n",
    "                elif start_time <= ((t_min[i] + t_max[i]) / 2) <= end_time:\n",
    "                    label[species_id[i]] = 1\n",
    "        \n",
    "        return {\n",
    "            \"waveform\" : y,\n",
    "            \"target\" : torch.tensor(label, dtype=torch.float),\n",
    "            \"id\" : recording_id\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TrainDataset(\n",
    "    train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, period=10, transforms=None, data_path=\"train\", train=True):\n",
    "        self.period = period\n",
    "        self.transforms = transforms\n",
    "        self.data_path = data_path\n",
    "        self.train = train\n",
    "        \n",
    "        self.recording_ids = df[\"recording_id\"].values\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.recording_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        recording_id = self.recording_ids[idx]\n",
    "        \n",
    "        y, sr = sf.read(f\"{self.data_path}/{recording_id}.flac\")\n",
    "        \n",
    "        len_y = len(y)\n",
    "        effective_length = sr * self.period\n",
    "        \n",
    "        y_ = []\n",
    "        i = 0\n",
    "        while i < len_y:\n",
    "            y__ = y[i:i+effective_length]\n",
    "            \n",
    "            if self.transforms:\n",
    "                y__ = self.transforms(samples=y__, sample_rate=sr)\n",
    "                \n",
    "            y_.append(y__)\n",
    "            i = i + effective_length\n",
    "        \n",
    "        y = np.stack(y_)\n",
    "\n",
    "        label = np.zeros(24, dtype='f')\n",
    "        \n",
    "        return {\n",
    "            \"waveform\" : y,\n",
    "            \"target\" : torch.tensor(label, dtype=torch.float),\n",
    "            \"id\" : recording_id\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class AudioDataset(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, test_df, train_batch_size=16, num_workers=2):\n",
    "        super().__init__()\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.num_workers = num_workers\n",
    "        dataset = TrainDataset(train_df)\n",
    "        self.train_dataset, self.val_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "        self.test_dataset = TestDataset(test_df)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.train_batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.train_batch_size)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from torch.nn.modules.pooling import AdaptiveAvgPool2d, AdaptiveMaxPool2d\n",
    "from torch import nn\n",
    "\n",
    "import timm\n",
    "from functools import partial\n",
    "\n",
    "encoder_params = {\n",
    "    \"resnet50d\" : {\n",
    "        \"features\" : 2048,\n",
    "        \"init_op\"  : partial(timm.models.resnest50d, pretrained=True, in_chans=1)\n",
    "    },\n",
    "}\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "def do_mixup(x, mixup_lambda):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes \n",
    "    (1, 3, 5, ...).\n",
    "\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n",
    "        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n",
    "    return out\n",
    "\n",
    "class AudioClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "            encoder=\"resnet50d\",\n",
    "            sample_rate=48_000,\n",
    "            window_size=2048,\n",
    "            hop_size=512,\n",
    "            mel_bins=128,\n",
    "            fmin=0,\n",
    "            fmax=24_000,\n",
    "            classes_num=24\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "        \n",
    "        self.encoder = encoder_params[encoder][\"init_op\"]()\n",
    "        self.avg_pool = AdaptiveAvgPool2d((1, 1))\n",
    "        #self.max_pool = AdaptiveMaxPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(encoder_params[encoder]['features'], classes_num)\n",
    "    \n",
    "    def forward(self, input, spec_aug=False, mixup_lambda=None):\n",
    "        #print(input.type())\n",
    "        x = self.spectrogram_extractor(input.float()) # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x) # (batch_size, 1, time_steps, mel_bins)\n",
    "\n",
    "        #if spec_aug:\n",
    "        #    x = self.spec_augmenter(x)\n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "        \n",
    "        # Mixup on spectrogram\n",
    "        if mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "            #pass\n",
    "        \n",
    "        x = self.encoder.forward_features(x)\n",
    "        x = self.avg_pool(x).flatten(1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class AudioClassifierModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            loss_fn=None,\n",
    "            learning_rate=1e-5,\n",
    "            model_parameters=None\n",
    "        ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.model = AudioClassifier(**model_parameters) if model_parameters else AudioClassifier()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = loss_fn\n",
    "        self.metrics = [torchmetrics.Accuracy()]\n",
    "\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = torch.optim.Adam(\n",
    "    #         [{\n",
    "    #             'params': [p for p in self.parameters()],\n",
    "    #             'name': 'my_parameter_group_name'\n",
    "    #         }],\n",
    "    #         lr=self.learning_rate\n",
    "    #     )\n",
    "    #     warmup_factor = 1.0 / 1000\n",
    "    #     warmup_iters = min(1000, self.data_len - 1)\n",
    "    #     def fun(iter_num: int) -> float:\n",
    "    #         if iter_num >= warmup_iters:\n",
    "    #             return 1\n",
    "    #         alpha = float(iter_num) / warmup_iters\n",
    "    #         return warmup_factor * (1 - alpha) + alpha\n",
    "    #     lr_scheduler = {\n",
    "    #         'scheduler': torch.optim.lr_scheduler.LambdaLR(optimizer, fun),\n",
    "    #         'name': 'learning_rate'\n",
    "    #     }\n",
    "    #     return [optimizer], [lr_scheduler]\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "            logits = self.model(x)\n",
    "            return logits\n",
    "\n",
    "    def _step(self, batch, stage=None):\n",
    "        if stage != \"test\":\n",
    "            output = self.model(batch['waveform'])        \n",
    "            loss = self.loss(output, batch['target'])\n",
    "\n",
    "            # for m in self.metrics:\n",
    "            #     m.update(batch['target'], output)\n",
    "            return {'loss': loss}\n",
    "        else:\n",
    "            pred_list = []\n",
    "            id_list = []\n",
    "            for x in batch[0]:\n",
    "                input = x[\"waveform\"]\n",
    "                bs, seq, w = input.shape\n",
    "                input = input.reshape(bs*seq, w)\n",
    "                id = x[\"id\"]\n",
    "                output = torch.sigmoid(self.model(input))\n",
    "                output = output.reshape(bs, seq, -1)\n",
    "                output, _ = torch.max(output, dim=1)\n",
    "                output = output.cpu().detach().numpy().tolist()\n",
    "                pred_list.extend(output)\n",
    "                id_list.extend(id)\n",
    "            return {\"preds\": pred_list, \"id\": id_list}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._step(batch, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clingier\\anaconda3\\envs\\rainforest\\lib\\site-packages\\torchlibrosa\\stft.py:193: FutureWarning: Pass size=2048 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "mod = AudioClassifierModule(loss_fn=BCEWithLogitsLoss())\n",
    "\n",
    "ds = AudioDataset(train, test)\n",
    "train_loader = ds.train_dataloader()\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(0.6949, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.training_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clingier\\anaconda3\\envs\\rainforest\\lib\\site-packages\\torchlibrosa\\stft.py:193: FutureWarning: Pass size=2048 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The parent should define the method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m litmodel \u001b[39m=\u001b[39m AudioClassifierModule(loss_fn\u001b[39m=\u001b[39mBCEWithLogitsLoss())\n\u001b[0;32m      4\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer()\n\u001b[1;32m----> 6\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(litmodel, dataset\u001b[39m.\u001b[39;49mtrain_dataloader(), dataset\u001b[39m.\u001b[39;49mval_dataloader())\n",
      "File \u001b[1;32mc:\\Users\\clingier\\anaconda3\\envs\\rainforest\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:552\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[0;32m    547\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[0;32m    548\u001b[0m )\n\u001b[0;32m    550\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_connector\u001b[39m.\u001b[39mresume_start()\n\u001b[1;32m--> 552\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model)\n\u001b[0;32m    554\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    555\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clingier\\anaconda3\\envs\\rainforest\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:849\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39mhparams\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    847\u001b[0m     parsing\u001b[39m.\u001b[39mclean_namespace(model\u001b[39m.\u001b[39mhparams)\n\u001b[1;32m--> 849\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_validator\u001b[39m.\u001b[39;49mverify_loop_configurations(model)\n\u001b[0;32m    851\u001b[0m \u001b[39m# attach model log function to callback\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_connector\u001b[39m.\u001b[39mattach_model_logging_functions(model)\n",
      "File \u001b[1;32mc:\\Users\\clingier\\anaconda3\\envs\\rainforest\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:34\u001b[0m, in \u001b[0;36mConfigValidator.verify_loop_configurations\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mChecks that the model is configured correctly before the run is started.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39min\u001b[39;00m (TrainerFn\u001b[39m.\u001b[39mFITTING, TrainerFn\u001b[39m.\u001b[39mTUNING):\n\u001b[1;32m---> 34\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__verify_train_loop_configuration(model)\n\u001b[0;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__verify_eval_loop_configuration(model, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__verify_manual_optimization_support(model)\n",
      "File \u001b[1;32mc:\\Users\\clingier\\anaconda3\\envs\\rainforest\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:49\u001b[0m, in \u001b[0;36mConfigValidator.__verify_train_loop_configuration\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__verify_train_loop_configuration\u001b[39m(\u001b[39mself\u001b[39m, model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[39m# -----------------------------------\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[39m# verify model has a training step\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[39m# -----------------------------------\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     has_training_step \u001b[39m=\u001b[39m is_overridden(\u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, model)\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_training_step:\n\u001b[0;32m     51\u001b[0m         \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[0;32m     52\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNo `training_step()` method defined. Lightning `Trainer` expects as minimum a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\clingier\\anaconda3\\envs\\rainforest\\lib\\site-packages\\pytorch_lightning\\utilities\\model_helpers.py:63\u001b[0m, in \u001b[0;36mis_overridden\u001b[1;34m(method_name, instance, parent, model)\u001b[0m\n\u001b[0;32m     61\u001b[0m parent_attr \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(parent, method_name, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     62\u001b[0m \u001b[39mif\u001b[39;00m parent_attr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe parent should define the method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[39m# cannot pickle `__code__` so cannot verify if `PatchDataloader`\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39m# exists which shows dataloader methods have been overwritten.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m# so, we hack it by using the string representation\u001b[39;00m\n\u001b[0;32m     68\u001b[0m instance_code \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(instance_attr, \u001b[39m\"\u001b[39m\u001b[39mpatch_loader_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m instance_attr\u001b[39m.\u001b[39m\u001b[39m__code__\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: The parent should define the method"
     ]
    }
   ],
   "source": [
    "dataset = AudioDataset(train, test)\n",
    "litmodel = AudioClassifierModule(loss_fn=BCEWithLogitsLoss())\n",
    "\n",
    "trainer = pl.Trainer()\n",
    "\n",
    "trainer.fit(litmodel, dataset.train_dataloader(), dataset.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainforest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d07cf21e036f5e9abbcd0eca41bc33306d5afe6659e695f5c8bf90db103e3501"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
